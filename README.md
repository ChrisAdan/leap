# Take the Leap

## ðŸ•¹ï¸ Project Overview

We're simulating an analytics infrastructure for leap, a simulated new online live service game looking to grow their player base. This take-home project demonstrates how to design and implement an end-to-end analytics pipeline, from synthetic data generation to modeling and insights, aligned with real-world analytical use cases like player retention, in-game monetization, and session-level behaviors.

The project focuses on:

- Simulating gameplay events using realistic mock data
- Designing an ingestion and transformation pipeline
- Modeling an analytics warehouse
- Enabling performant, business-critical queries

---

## ðŸ“¦ Pipeline Overview

| Stage         | Tooling         | Description                                                                                                                    |
| ------------- | --------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| Data Gen      | `main.py`       | Orchestrates all generators (sessions, transactions, products, heartbeats) to produce realistic JSON/CSV event data            |
| Ingest & Load | Python + DuckDB | Loads generated raw event data into `leap_raw` tables in DuckDB                                                                |
| Transform     | dbt             | Transforms raw data through `leap_stage` and `leap_dim` into `leap_mart` models using game-aware logic (e.g., close conflicts) |
| Analysis      | SQL + Jupyter   | Runs performant analytical queries and produces insights from `leap_mart` tables                                               |

---

## ðŸ§ª Simulated Event Sources

We simulate three primary logging sources reflecting real-time game telemetry:

1. **Session Ends**  
   player_id, session_id, event_date_time, country, event_length_seconds, kills, deaths

2. **In-Game Purchases**  
   transaction_id, player_id, event_date_time, purchase_item, purchase_price, currency, is_recurring, cycle, transaction_type (Battle Pass, Skins, Emotes)

3. **Player Heartbeats**  
   player_id, event_date_time, team_id, session_id, position_x, position_y, position_z

Each player plays at most 1 session per day due to computation constraints. Heartbeats are generated every 30s during active sessions. Purchase behavior varies by player cluster.

---

## ðŸ§  Analytics Goals

The data model and pipeline are built to enable analysts to answer:

- Daily/weekly/monthly player activity trends
- Player lifecycle metrics (kills/deaths, revenue, streaks)
- Engagement by region
- Real-time game dynamics like **close conflicts**

Close conflicts are derived from heartbeat data in dbt using spatial proximity and time gap logic.

---

## âš™ï¸ How To Use Locally

Follow these steps to clone the repo, set up a Python virtual environment, generate synthetic data, and run the full dbt analytics pipeline on your machine:

```bash
# 1. Clone the repository
git clone https://github.com/ChrisAdan/leap.git leap
cd leap

# 2. Create and activate a Python virtual environment
python3 -m venv .venv
source .venv/bin/activate       # On Windows: venv\Scripts\activate

# 3. Install Python dependencies
pip install -r requirements.txt

# 4. Install project in editable mode
pip install -e .

# 5. Generate all synthetic data (players, sessions, transactions, etc.)
python scripts/main.py --entrypoint all

# 6. Run dbt to build models and tests
dbt deps
dbt compile
dbt run
dbt test

# 7. Generate and serve dbt documentation site
dbt docs generate
dbt docs serve
```

# ðŸ’¡ Notes

[ ] This setup assumes you have Python and dbt installed and available in your PATH.  
[ ] All generated data is loaded into the local DuckDB database configured in the project.  
[ ] You can adjust data generation by specifying different --entrypoint options to main.py.

To stop serving docs, press Ctrl+C in the terminal running dbt docs serve.

---

## ðŸ“– Hosted Documentation

Explore the full interactive dbt documentation and data lineage for this project online at:

[GitHub Pages](https://chrisadan.github.io/leap)

This GitHub Pages site is automatically updated from the `gh-pages` branch containing the latest dbt docs generated by the pipeline.

---

## ðŸ—‚ï¸ Folder Structure

```bash
leap/                         # Root project directory
â”‚
â”œâ”€â”€ data/                       # Output folder for synthetic JSON/CSV/Parquet data
â”‚   â””â”€â”€ sessions/                # JSON dumps for player sessions
â”‚
â”œâ”€â”€ scripts/                    # CLI entry points for the pipeline
â”‚   â””â”€â”€ main.py                  # Orchestrates all data generation and ingestion
â”‚
â”œâ”€â”€ src/                        # Core simulation logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ session_generator.py     # Creates player sessions and metadata
â”‚   â”œâ”€â”€ heartbeat_generator.py   # Simulates player movement heartbeats in 3D space
â”‚   â”œâ”€â”€ transaction_generator.py # Simulates in-game purchase transactions
â”‚   â”œâ”€â”€ loader.py                # Loads generated data into DuckDB
â”‚   â”œâ”€â”€ summarizer.py            # Aggregates kills, deaths, session stats
â”‚   â”œâ”€â”€ utils.py                 # Shared helper functions
â”‚   â”œâ”€â”€ movement/                # Movement function implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ step/
â”‚   â”‚       â”œâ”€â”€ lorentzian.py
â”‚   â”‚       â”œâ”€â”€ bezier.py
â”‚   â”‚       â”œâ”€â”€ lissajous.py
â”‚   â”‚       â”œâ”€â”€ perlin.py
â”‚   â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ dbt_project/                 # dbt transformations
â”‚   â”œâ”€â”€ seeds/                   # Static ref data from product_generator.py
â”‚   â”‚   â””â”€â”€ dim_products.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â”œâ”€â”€ event_heartbeat.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stage_centroids.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stage_conflicts.sql
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ marts/
â”‚   â”‚   â”‚   â”œâ”€â”€ country_monthly_playtime.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ country_weekly_revenue.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ conflict_summary_daily.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ player_activity_daily.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ player_consecutive_days_monthly.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ player_stats_lifetime.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ session_close_conflicts_daily.sql
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚
â”‚   â”œâ”€â”€ macros/
â”‚   â”‚   â””â”€â”€ compute_conflicts.sql
â”‚
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ no_zero_duration_conflicts.sql
â”‚   â”‚   â”œâ”€â”€ country_referential_integrity.sql
â”‚   â”‚   â”œâ”€â”€ non_negative_playtime.sql
â”‚   â”‚   â”œâ”€â”€ revenue_consistency_weekly.sql
â”‚   â”‚   â”œâ”€â”€ test_activity_matches_heartbeats.sql
â”‚   â”‚   â””â”€â”€ test_consecutive_days_within_month.sql
â”‚
â”œâ”€â”€ tests/                       # Pytest unit tests
â”‚   â”œâ”€â”€ test_db.py
â”‚   â”œâ”€â”€ test_products.py
â”‚   â”œâ”€â”€ test_sessions.py
â”‚   â””â”€â”€ test_transactions.py
â”‚
â”œâ”€â”€ notebooks/                   # Analysis notebooks
â”‚   â””â”€â”€ player_paths.ipynb
â”‚
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ðŸ§± Data Warehouse Design

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python&logoColor=white&style=flat-square) |
![DuckDB](https://img.shields.io/badge/DuckDB-%231C2D3F?logo=DuckDB&logoColor=white&style=flat-square) |
![dbt](https://img.shields.io/badge/dbt-%23FF694B?logo=dbt&logoColor=white&style=flat-square)

**Schema & Table Catalog**

**leap_dim**

- dim_players
- dim_products

**leap_mart**

- country_monthly_playtime
- country_weekly_revenue
- conflict_summary_daily
- player_activity_daily
- player_consecutive_days_monthly
- player_stats_lifetime
- session_close_conflicts_daily

**leap_raw**

- event_session
- event_signons
- event_transaction

**leap_stage**

- event_heartbeat
- fact_session
- stage_centroids
- stage_conflicts

---

## ðŸ“Š Analysis

Analysis is performed in Jupyter notebooks and SQL, targeting `leap_mart` tables to answer gameplay and business questions with performant queries.

---

## ðŸš€ Coming Up Next

- [x] End-to-end pipeline: data generation â†’ ingestion â†’ transformation â†’ marts
- [x] dbt models for conflicts, centroids, and session facts
- [x] Analytical queries for business/gameplay metrics
- [ ] Better player generation â€” modeling churn, retention, and realistic growth
- [ ] Player profiling â€” generate realistic player metadata with Faker
- [ ] Machine learning â€” predictive analytics (random forest, logistic regression, XGBoost) on player purchase behavior to identify targetable sales segments

## ðŸ“£ Stay Connected

[![Read on Medium](https://img.shields.io/badge/Read%20on-Medium-black?logo=medium)](https://upandtothewrite.medium.com/)
[![Find Me on LinkedIn](https://img.shields.io/badge/Connect-LinkedIn-blue?logo=linkedin)](https://www.linkedin.com/in/chrisadan/)

---

> ðŸ“Œ **Note**: This project demonstrates analytics pipeline design and implementation for a simulated gaming environment. All code, implementation details, and architectural decisions are original work created for educational and demonstration purposes only.

```bash
This README was autogenerated by Claude.ai
```
